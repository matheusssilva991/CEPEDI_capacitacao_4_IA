{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-22 21:36:25.598635: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score,\n",
    "                             recall_score)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconhecimento de Imagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: (64, 64, 1)\n",
      "num_classes: 40\n",
      "\n",
      "X_train.shape: (320, 64, 64),\tX_test.shape: (80, 64, 64)\n",
      "y_train.shape: (320, 40),\ty_test.shape: (80, 40)\n"
     ]
    }
   ],
   "source": [
    "# Carregar o dataset\n",
    "dataset = fetch_olivetti_faces(shuffle=True, random_state=42)\n",
    "\n",
    "# Dividir o dataset em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.images, dataset.target, test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Converter os dados para o formato correto\n",
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "\n",
    "# Definir vari√°veis globais\n",
    "INPUT_SHAPE = (X_train.shape[1], X_train.shape[2], 1, )\n",
    "NUM_CLASSES = y_train.shape[1]\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(f\"input_shape: {INPUT_SHAPE}\\n\" \\\n",
    "      f\"num_classes: {NUM_CLASSES}\\n\")\n",
    "\n",
    "print(f\"X_train.shape: {X_train.shape},\\t\" \\\n",
    "      f\"X_test.shape: {X_test.shape}\\n\" \\\n",
    "      f\"y_train.shape: {y_train.shape},\\t\" \\\n",
    "      f\"y_test.shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-22 21:36:27.071244: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 37ms/step - loss: 4.0423 - accuracy: 0.0344\n",
      "Epoch 2/25\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 3.6713 - accuracy: 0.0938\n",
      "Epoch 3/25\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 3.1396 - accuracy: 0.3000\n",
      "Epoch 4/25\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 2.6087 - accuracy: 0.6500\n",
      "Epoch 5/25\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 1.9403 - accuracy: 0.8594\n",
      "Epoch 6/25\n",
      "10/10 [==============================] - 0s 45ms/step - loss: 1.2513 - accuracy: 0.9406\n",
      "Epoch 7/25\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.7979 - accuracy: 0.9406\n",
      "Epoch 8/25\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.5349 - accuracy: 0.9656\n",
      "Epoch 9/25\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 0.3615 - accuracy: 0.9719\n",
      "Epoch 10/25\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.2353 - accuracy: 0.9844\n",
      "Epoch 11/25\n",
      "10/10 [==============================] - 0s 37ms/step - loss: 0.1654 - accuracy: 0.9906\n",
      "Epoch 12/25\n",
      "10/10 [==============================] - 0s 43ms/step - loss: 0.1264 - accuracy: 0.9969\n",
      "Epoch 13/25\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.0951 - accuracy: 0.9969\n",
      "Epoch 14/25\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.0753 - accuracy: 1.0000\n",
      "Epoch 15/25\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.0677 - accuracy: 1.0000\n",
      "Epoch 16/25\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.0534 - accuracy: 1.0000\n",
      "Epoch 17/25\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.0414 - accuracy: 1.0000\n",
      "Epoch 18/25\n",
      "10/10 [==============================] - 0s 42ms/step - loss: 0.0380 - accuracy: 1.0000\n",
      "Epoch 19/25\n",
      "10/10 [==============================] - 0s 42ms/step - loss: 0.0331 - accuracy: 1.0000\n",
      "Epoch 20/25\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.0282 - accuracy: 1.0000\n",
      "Epoch 21/25\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.0254 - accuracy: 1.0000\n",
      "Epoch 22/25\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 23/25\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 24/25\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.0190 - accuracy: 1.0000\n",
      "Epoch 25/25\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.0177 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Definindo o modelo\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, kernel_size = (3, 3), activation='relu', input_shape=INPUT_SHAPE))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss = 'categorical_crossentropy',\n",
    "        optimizer = 'adam',\n",
    "        metrics = [\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Treinando o modelo\n",
    "try :\n",
    "    model = load_model(\"../models/model.h5\")\n",
    "except:\n",
    "    model = build_model()\n",
    "    history = model.fit(X_train, y_train, epochs=25, batch_size=BATCH_SIZE)\n",
    "    model.save(\"../models/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n",
      "Accuracy: 0.9375\n",
      "Precision: 0.9704761904761904\n",
      "Recall: 0.95\n",
      "F1: 0.9493424036281177\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict = np.argmax(model.predict(X_test), axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, predict)}\\n\" \\\n",
    "        f\"Precision: {precision_score(y_test, predict, average='macro')}\\n\" \\\n",
    "        f\"Recall: {recall_score(y_test, predict, average='macro')}\\n\" \\\n",
    "        f\"F1: {f1_score(y_test, predict, average='macro')}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cepedi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
